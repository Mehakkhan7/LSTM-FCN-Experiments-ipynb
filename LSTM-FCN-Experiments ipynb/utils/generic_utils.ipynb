{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "mpl.style.use('seaborn-paper')\n",
    "\n",
    "from utils.constants import TRAIN_FILES, TEST_FILES, MAX_SEQUENCE_LENGTH_LIST, NB_CLASSES_LIST\n",
    "\n",
    "\n",
    "def load_dataset_at(index, normalize_timeseries=False, verbose=True) -> (np.array, np.array):\n",
    "    \"\"\"\n",
    "    Loads a Univaraite UCR Dataset indexed by `utils.constants`.\n",
    "\n",
    "    Args:\n",
    "        index: Integer index, set inside `utils.constants` that refers to the\n",
    "            dataset.\n",
    "        normalize_timeseries: Bool / Integer. Determines whether to normalize\n",
    "            the timeseries.\n",
    "\n",
    "            If False, does not normalize the time series.\n",
    "            If True / int not equal to 2, performs standard sample-wise\n",
    "                z-normalization.\n",
    "            If 2: Performs full dataset z-normalization.\n",
    "        verbose: Whether to describe the dataset being loaded.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of shape (X_train, y_train, X_test, y_test, is_timeseries).\n",
    "        For legacy reasons, is_timeseries is always True.\n",
    "    \"\"\"\n",
    "    assert index < len(TRAIN_FILES), \"Index invalid. Could not load dataset at %d\" % index\n",
    "    if verbose: print(\"Loading train / test dataset : \", TRAIN_FILES[index], TEST_FILES[index])\n",
    "\n",
    "    if os.path.exists(TRAIN_FILES[index]):\n",
    "        df = pd.read_csv(TRAIN_FILES[index], header=None, encoding='latin-1')\n",
    "\n",
    "    elif os.path.exists(TRAIN_FILES[index][1:]):\n",
    "        df = pd.read_csv(TRAIN_FILES[index][1:], header=None, encoding='latin-1')\n",
    "\n",
    "    else:\n",
    "        raise FileNotFoundError('File %s not found!' % (TRAIN_FILES[index]))\n",
    "\n",
    "    is_timeseries = True # assume all input data is univariate time series\n",
    "\n",
    "    # remove all columns which are completely empty\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "    if not is_timeseries:\n",
    "        data_idx = df.columns[1:]\n",
    "        min_val = min(df.loc[:, data_idx].min())\n",
    "        if min_val == 0:\n",
    "            df.loc[:, data_idx] += 1\n",
    "\n",
    "    # fill all missing columns with 0\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # cast all data into integer (int32)\n",
    "    if not is_timeseries:\n",
    "        df[df.columns] = df[df.columns].astype(np.int32)\n",
    "\n",
    "    # extract labels Y and normalize to [0 - (MAX - 1)] range\n",
    "    y_train = df[[0]].values\n",
    "    nb_classes = len(np.unique(y_train))\n",
    "    y_train = (y_train - y_train.min()) / (y_train.max() - y_train.min()) * (nb_classes - 1)\n",
    "\n",
    "    # drop labels column from train set X\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    X_train = df.values\n",
    "\n",
    "    if is_timeseries:\n",
    "        X_train = X_train[:, np.newaxis, :]\n",
    "        # scale the values\n",
    "        if normalize_timeseries:\n",
    "            normalize_timeseries = int(normalize_timeseries)\n",
    "\n",
    "            if normalize_timeseries == 2:\n",
    "                X_train_mean = X_train.mean()\n",
    "                X_train_std = X_train.std()\n",
    "                X_train = (X_train - X_train_mean) / (X_train_std + 1e-8)\n",
    "\n",
    "            else:\n",
    "                X_train_mean = X_train.mean(axis=-1, keepdims=True)\n",
    "                X_train_std = X_train.std(axis=-1, keepdims=True)\n",
    "                X_train = (X_train - X_train_mean) / (X_train_std + 1e-8)\n",
    "\n",
    "    if verbose: print(\"Finished loading train dataset..\")\n",
    "\n",
    "    if os.path.exists(TEST_FILES[index]):\n",
    "        df = pd.read_csv(TEST_FILES[index], header=None, encoding='latin-1')\n",
    "\n",
    "    elif os.path.exists(TEST_FILES[index][1:]):\n",
    "        df = pd.read_csv(TEST_FILES[index][1:], header=None, encoding='latin-1')\n",
    "    else:\n",
    "        raise FileNotFoundError('File %s not found!' % (TEST_FILES[index]))\n",
    "\n",
    "    # remove all columns which are completely empty\n",
    "    df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "    if not is_timeseries:\n",
    "        data_idx = df.columns[1:]\n",
    "        min_val = min(df.loc[:, data_idx].min())\n",
    "        if min_val == 0:\n",
    "            df.loc[:, data_idx] += 1\n",
    "\n",
    "    # fill all missing columns with 0\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # cast all data into integer (int32)\n",
    "    if not is_timeseries:\n",
    "        df[df.columns] = df[df.columns].astype(np.int32)\n",
    "\n",
    "    # extract labels Y and normalize to [0 - (MAX - 1)] range\n",
    "    y_test = df[[0]].values\n",
    "    nb_classes = len(np.unique(y_test))\n",
    "    y_test = (y_test - y_test.min()) / (y_test.max() - y_test.min()) * (nb_classes - 1)\n",
    "\n",
    "    # drop labels column from train set X\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    X_test = df.values\n",
    "\n",
    "    if is_timeseries:\n",
    "        X_test = X_test[:, np.newaxis, :]\n",
    "        # scale the values\n",
    "        if normalize_timeseries:\n",
    "            normalize_timeseries = int(normalize_timeseries)\n",
    "\n",
    "            if normalize_timeseries == 2:\n",
    "                X_test = (X_test - X_train_mean) / (X_train_std + 1e-8)\n",
    "            else:\n",
    "                X_test_mean = X_test.mean(axis=-1, keepdims=True)\n",
    "                X_test_std = X_test.std(axis=-1, keepdims=True)\n",
    "                X_test = (X_test - X_test_mean) / (X_test_std + 1e-8)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Finished loading test dataset..\")\n",
    "        print()\n",
    "        print(\"Number of train samples : \", X_train.shape[0], \"Number of test samples : \", X_test.shape[0])\n",
    "        print(\"Number of classes : \", nb_classes)\n",
    "        print(\"Sequence length : \", X_train.shape[-1])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, is_timeseries\n",
    "\n",
    "\n",
    "def calculate_dataset_metrics(X_train):\n",
    "    \"\"\"\n",
    "    Calculates the dataset metrics used for model building and evaluation.\n",
    "\n",
    "    Args:\n",
    "        X_train: The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (None, sequence_length). None is for legacy\n",
    "        purposes.\n",
    "    \"\"\"\n",
    "    is_timeseries = len(X_train.shape) == 3\n",
    "    if is_timeseries:\n",
    "        # timeseries dataset\n",
    "        max_sequence_length = X_train.shape[-1]\n",
    "        max_nb_words = None\n",
    "    else:\n",
    "        # transformed dataset\n",
    "        max_sequence_length = X_train.shape[-1]\n",
    "        max_nb_words = np.amax(X_train) + 1\n",
    "\n",
    "    return max_nb_words, max_sequence_length\n",
    "\n",
    "\n",
    "def plot_dataset(dataset_id, seed=None, limit=None, cutoff=None,\n",
    "                 normalize_timeseries=False, plot_data=None,\n",
    "                 type='Context', plot_classwise=False):\n",
    "    \"\"\"\n",
    "    Util method to plot a dataset under several possibilities.\n",
    "\n",
    "    Args:\n",
    "        dataset_id: Integer id, refering to the dataset set inside\n",
    "            `utils/constants.py`.\n",
    "        seed: Numpy Random seed.\n",
    "        limit: Number of data points to be visualized. Min of 1.\n",
    "        cutoff: Optional integer which slices of the first `cutoff` timesteps\n",
    "            from the input signal.\n",
    "        normalize_timeseries: Bool / Integer. Determines whether to normalize\n",
    "            the timeseries.\n",
    "\n",
    "            If False, does not normalize the time series.\n",
    "            If True / int not equal to 2, performs standard sample-wise\n",
    "                z-normalization.\n",
    "            If 2: Performs full dataset z-normalization.\n",
    "        plot_data: Additional data used for plotting in place of the\n",
    "            loaded train set. Can be the test set or some other val set.\n",
    "        type: Type of plot being built. Can be one of ['Context', any other string].\n",
    "            Context is a specific keyword, used for Context from Attention LSTM.\n",
    "            If any other string is provided, it is used in the title.\n",
    "        plot_classwise: Bool flag. Wheter to visualize the samples\n",
    "            seperated by class. When doing so, `limit` is multiplied by\n",
    "            the number of classes so it is better to set `limit` to 1 in\n",
    "            such cases\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    if plot_data is None:\n",
    "        X_train, y_train, X_test, y_test, is_timeseries = load_dataset_at(\n",
    "                                                               dataset_id,\n",
    "                                                               normalize_timeseries=normalize_timeseries)\n",
    "\n",
    "        if not is_timeseries:\n",
    "            print(\"Can plot time series input data only!\\n\"\n",
    "                  \"Continuing without plot!\")\n",
    "            return\n",
    "\n",
    "        max_nb_words, sequence_length = calculate_dataset_metrics(X_train)\n",
    "\n",
    "        if sequence_length != MAX_SEQUENCE_LENGTH_LIST[dataset_id]:\n",
    "            if cutoff is None:\n",
    "                choice = cutoff_choice(dataset_id, sequence_length)\n",
    "            else:\n",
    "                assert cutoff in ['pre', 'post'], 'Cutoff parameter value must be either \"pre\" or \"post\"'\n",
    "                choice = cutoff\n",
    "\n",
    "            if choice not in ['pre', 'post']:\n",
    "                return\n",
    "            else:\n",
    "                X_train, X_test = X_test(X_train, X_test, choice, dataset_id, sequence_length)\n",
    "\n",
    "        X_train_attention = None\n",
    "        X_test_attention = None\n",
    "\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test, X_train_attention, X_test_attention = plot_data\n",
    "\n",
    "    if limit is None:\n",
    "        train_size = X_train.shape[0]\n",
    "        test_size = X_test.shape[0]\n",
    "    else:\n",
    "        if not plot_classwise:\n",
    "            train_size = limit\n",
    "            test_size = limit\n",
    "        else:\n",
    "            assert limit == 1, 'If plotting classwise, limit must be 1 so as to ensure number of samples per class = 1'\n",
    "            train_size = NB_CLASSES_LIST[dataset_id] * limit\n",
    "            test_size = NB_CLASSES_LIST[dataset_id] * limit\n",
    "\n",
    "    if not plot_classwise:\n",
    "        train_idx = np.random.randint(0, X_train.shape[0], size=train_size)\n",
    "        X_train = X_train[train_idx, 0, :]\n",
    "        X_train = X_train.transpose((1, 0))\n",
    "\n",
    "        if X_train_attention is not None:\n",
    "            X_train_attention = X_train_attention[train_idx, 0, :]\n",
    "            X_train_attention = X_train_attention.transpose((1, 0))\n",
    "    else:\n",
    "        classwise_train_list = []\n",
    "        for y_ in sorted(np.unique(y_train[:, 0])):\n",
    "            class_train_idx = np.where(y_train[:, 0] == y_)\n",
    "            classwise_train_list.append(class_train_idx[:])\n",
    "\n",
    "        classwise_sample_size_list = [len(x[0]) for x in classwise_train_list]\n",
    "        size = min(classwise_sample_size_list)\n",
    "        train_size = min([train_size // NB_CLASSES_LIST[dataset_id], size])\n",
    "\n",
    "        for i in range(len(classwise_train_list)):\n",
    "            classwise_train_idx = np.random.randint(0, len(classwise_train_list[i][0]), size=train_size)\n",
    "            classwise_train_list[i] = classwise_train_list[i][0][classwise_train_idx]\n",
    "\n",
    "        classwise_X_train_list = []\n",
    "        classwise_X_train_attention_list = []\n",
    "\n",
    "        for classwise_train_idx in classwise_train_list:\n",
    "            classwise_X = X_train[classwise_train_idx, 0, :]\n",
    "            classwise_X = classwise_X.transpose((1, 0))\n",
    "            classwise_X_train_list.append(classwise_X)\n",
    "\n",
    "            if X_train_attention is not None:\n",
    "                classwise_X_attn = X_train_attention[classwise_train_idx, 0, :]\n",
    "                classwise_X_attn = classwise_X_attn.transpose((1, 0))\n",
    "                classwise_X_train_attention_list.append(classwise_X_attn)\n",
    "\n",
    "        classwise_X_train_list = [np.asarray(x) for x in classwise_X_train_list]\n",
    "        classwise_X_train_attention_list = [np.asarray(x) for x in classwise_X_train_attention_list]\n",
    "\n",
    "        # classwise x train\n",
    "        X_train = np.concatenate(classwise_X_train_list, axis=-1)\n",
    "\n",
    "        # classwise x train attention\n",
    "        if X_train_attention is not None:\n",
    "            X_train_attention = np.concatenate(classwise_X_train_attention_list, axis=-1)\n",
    "\n",
    "    if not plot_classwise:\n",
    "        test_idx = np.random.randint(0, X_test.shape[0], size=test_size)\n",
    "        X_test = X_test[test_idx, 0, :]\n",
    "        X_test = X_test.transpose((1, 0))\n",
    "\n",
    "        if X_test_attention is not None:\n",
    "            X_test_attention = X_test_attention[test_idx, 0, :]\n",
    "            X_test_attention = X_test_attention.transpose((1, 0))\n",
    "    else:\n",
    "        classwise_test_list = []\n",
    "        for y_ in sorted(np.unique(y_test[:, 0])):\n",
    "            class_test_idx = np.where(y_test[:, 0] == y_)\n",
    "            classwise_test_list.append(class_test_idx[:])\n",
    "\n",
    "        classwise_sample_size_list = [len(x[0]) for x in classwise_test_list]\n",
    "        size = min(classwise_sample_size_list)\n",
    "        test_size = min([test_size // NB_CLASSES_LIST[dataset_id], size])\n",
    "\n",
    "        for i in range(len(classwise_test_list)):\n",
    "            classwise_test_idx = np.random.randint(0, len(classwise_test_list[i][0]), size=test_size)\n",
    "            classwise_test_list[i] = classwise_test_list[i][0][classwise_test_idx]\n",
    "\n",
    "        classwise_X_test_list = []\n",
    "        classwise_X_test_attention_list = []\n",
    "\n",
    "        for classwise_test_idx in classwise_test_list:\n",
    "            classwise_X = X_test[classwise_test_idx, 0, :]\n",
    "            classwise_X = classwise_X.transpose((1, 0))\n",
    "            classwise_X_test_list.append(classwise_X)\n",
    "\n",
    "            if X_test_attention is not None:\n",
    "                classwise_X_attn = X_test_attention[classwise_test_idx, 0, :]\n",
    "                classwise_X_attn = classwise_X_attn.transpose((1, 0))\n",
    "                classwise_X_test_attention_list.append(classwise_X_attn)\n",
    "\n",
    "        classwise_X_test_list = [np.asarray(x) for x in classwise_X_test_list]\n",
    "        classwise_X_test_attention_list = [np.asarray(x) for x in classwise_X_test_attention_list]\n",
    "\n",
    "        # classwise x test\n",
    "        X_test = np.concatenate(classwise_X_test_list, axis=-1)\n",
    "\n",
    "        # classwise x test attention\n",
    "        if X_test_attention is not None:\n",
    "            X_test_attention = np.concatenate(classwise_X_test_attention_list, axis=-1)\n",
    "\n",
    "    print('X_train shape : ', X_train.shape)\n",
    "    print('X_test shape : ', X_test.shape)\n",
    "\n",
    "    columns = ['Class %d' % (i + 1) for i in range(X_train.shape[1])]\n",
    "    train_df = pd.DataFrame(X_train,\n",
    "                            index=range(X_train.shape[0]),\n",
    "                            columns=columns)\n",
    "\n",
    "    test_df = pd.DataFrame(X_test,\n",
    "                           index=range(X_test.shape[0]),\n",
    "                           columns=columns)\n",
    "\n",
    "    if plot_data is not None:\n",
    "        rows = 2\n",
    "        cols = 2\n",
    "    else:\n",
    "        rows = 1\n",
    "        cols = 2\n",
    "\n",
    "    fig, axs = plt.subplots(rows, cols, squeeze=False,\n",
    "                           tight_layout=True, figsize=(8, 6))\n",
    "    axs[0][0].set_title('Train dataset', size=16)\n",
    "    axs[0][0].set_xlabel('timestep')\n",
    "    axs[0][0].set_ylabel('value')\n",
    "    train_df.plot(subplots=False,\n",
    "                  legend='best',\n",
    "                  ax=axs[0][0],)\n",
    "\n",
    "    axs[0][1].set_title('Test dataset', size=16)\n",
    "    axs[0][1].set_xlabel('timestep')\n",
    "    axs[0][1].set_ylabel('value')\n",
    "    test_df.plot(subplots=False,\n",
    "                 legend='best',\n",
    "                 ax=axs[0][1],)\n",
    "\n",
    "    if plot_data is not None and X_train_attention is not None:\n",
    "        columns = ['Class %d' % (i + 1) for i in range(X_train_attention.shape[1])]\n",
    "        train_attention_df = pd.DataFrame(X_train_attention,\n",
    "                            index=range(X_train_attention.shape[0]),\n",
    "                            columns=columns)\n",
    "\n",
    "        axs[1][0].set_title('Train %s Sequence' % (type), size=16)\n",
    "        axs[1][0].set_xlabel('timestep')\n",
    "        axs[1][0].set_ylabel('value')\n",
    "        train_attention_df.plot(subplots=False,\n",
    "                                legend='best',\n",
    "                                ax=axs[1][0])\n",
    "\n",
    "    if plot_data is not None and X_test_attention is not None:\n",
    "        columns = ['Class %d' % (i + 1) for i in range(X_test_attention.shape[1])]\n",
    "        test_df = pd.DataFrame(X_test_attention,\n",
    "                               index=range(X_test_attention.shape[0]),\n",
    "                               columns=columns)\n",
    "\n",
    "        axs[1][1].set_title('Test %s Sequence' % (type), size=16)\n",
    "        axs[1][1].set_xlabel('timestep')\n",
    "        axs[1][1].set_ylabel('value')\n",
    "        test_df.plot(subplots=False,\n",
    "                     legend='best',\n",
    "                     ax=axs[1][1])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def cutoff_choice(dataset_id, sequence_length):\n",
    "    \"\"\"\n",
    "    Helper to allow the user to select whether they want to cutoff timesteps or not,\n",
    "    and in what manner (pre or post).\n",
    "\n",
    "    Args:\n",
    "        dataset_id: Dataset ID\n",
    "        sequence_length: Length of the sequence originally.\n",
    "\n",
    "    Returns:\n",
    "        String choice of pre or post slicing.\n",
    "    \"\"\"\n",
    "    print(\"Original sequence length was :\", sequence_length, \"New sequence Length will be : \",\n",
    "          MAX_SEQUENCE_LENGTH_LIST[dataset_id])\n",
    "    choice = input('Options : \\n'\n",
    "                   '`pre` - cut the sequence from the beginning\\n'\n",
    "                   '`post`- cut the sequence from the end\\n'\n",
    "                   '`anything else` - stop execution\\n'\n",
    "                   'To automate choice: add flag `cutoff` = choice as above\\n'\n",
    "                   'Choice = ')\n",
    "\n",
    "    choice = str(choice).lower()\n",
    "    return choice\n",
    "\n",
    "\n",
    "def cutoff_sequence(X_train, X_test, choice, dataset_id, sequence_length):\n",
    "    \"\"\"\n",
    "    Slices of the first `cutoff` timesteps from the input signal.\n",
    "\n",
    "    Args:\n",
    "        X_train: Train sequences.\n",
    "        X_test: Test sequences.\n",
    "        choice: User's choice of slicing method.\n",
    "        dataset_id: Integer id of the dataset set inside `utils/constants.py`.\n",
    "        sequence_length: Original length of the sequence.\n",
    "\n",
    "    Returns:\n",
    "        A tuple of (X_train, X_test) after slicing off the requisit number of\n",
    "        timesteps.\n",
    "    \"\"\"\n",
    "    assert MAX_SEQUENCE_LENGTH_LIST[dataset_id] < sequence_length, \"If sequence is to be cut, max sequence\" \\\n",
    "                                                                   \"length must be less than original sequence length.\"\n",
    "    cutoff = sequence_length - MAX_SEQUENCE_LENGTH_LIST[dataset_id]\n",
    "    if choice == 'pre':\n",
    "        if X_train is not None:\n",
    "            X_train = X_train[:, :, cutoff:]\n",
    "        if X_test is not None:\n",
    "            X_test = X_test[:, :, cutoff:]\n",
    "    else:\n",
    "        if X_train is not None:\n",
    "            X_train = X_train[:, :, :-cutoff]\n",
    "        if X_test is not None:\n",
    "            X_test = X_test[:, :, :-cutoff]\n",
    "    print(\"New sequence length :\", MAX_SEQUENCE_LENGTH_LIST[dataset_id])\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    word_list = []\n",
    "    seq_len_list = []\n",
    "    classes = []\n",
    "\n",
    "    # for index in range(85, 128):\n",
    "    #\n",
    "    #     x, y, x_test, y_test, is_timeseries = load_dataset_at(index)\n",
    "    #     nb_words, seq_len = calculate_dataset_metrics(x)\n",
    "    #     print(\"-\" * 80)\n",
    "    #     print(\"Dataset : \", index + 1)\n",
    "    #     print(\"Train :: X shape : \", x.shape, \"Y shape : \", y.shape, \"Nb classes : \", len(np.unique(y)))\n",
    "    #     print(\"Test :: X shape : \", x_test.shape, \"Y shape : \", y_test.shape, \"Nb classes : \", len(np.unique(y)))\n",
    "    #     print(\"Classes : \", np.unique(y))\n",
    "    #     print()\n",
    "    #\n",
    "    #     word_list.append(nb_words)\n",
    "    #     seq_len_list.append(seq_len)\n",
    "    #     classes.append(len(np.unique(y)))\n",
    "    #\n",
    "    # print(\"Word List : \", word_list)\n",
    "    # print(\"Sequence length list : \", seq_len_list)\n",
    "    # print(\"Max number of classes : \", classes)\n",
    "\n",
    "    plot_dataset(dataset_id=77, seed=1, limit=1, cutoff=None, normalize_timeseries=True,\n",
    "                 plot_classwise=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
